<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shang-Fu Chen</title>
  
  <meta name="author" content="Shang-Fu Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shang-Fu Chen</name>
              </p>
              <p>I am a fresh Ph.D. graduate from <a href="https://www.ntu.edu.tw/">National Taiwan University</a> under the supervision of Prof. <a href="https://shaohua0116.github.io/">Shao-Hua Sun</a>.  </p>
              <p>
                I completed my bachelor's degree in Electronic Engineering at NTU. During my Ph.D., I previously worked in the <a href="http://vllab.ee.ntu.edu.tw/">Vision and Learning Lab at NTU</a> and collaborated with Chunghwa Telecom Laboratories. I also worked with Inventec AI Center during my internship.
              </p>
              <p style="text-align:center">
                <a href="mailto:sam145637890@gmail.com">Email</a> &nbsp/&nbsp
                <a href="assets/CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com.tw/citations?user=ZKOpgs4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ShangfuChen">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="img/sfchen_personal.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="img/sfchen_personal.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
	            <heading>Research</heading>
	          
              <p>
            I'm interested in reinforcement learning, computer vision, and machine learning. My research is about utilizing machine learning techniques to solve application problems, including multi-label classification, anomaly detection, and imitation learning. 
              </p>
            </td>
          </tr>
        </tbody></table>
        

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr>
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <img src='img/dbc.png' style="max-width:120%;height:auto">
        </div>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <papertitle>HERO: Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning</papertitle>
        <be>
	Ayano Hiranaka*,<strong>Shang-Fu Chen*</strong>, Chieh-Hsin Lai*, Dongjun Kim, Naoki Murata, Takashi Shibuya, Wei-Hsiang Liao, Shao-Hua Sun‚Ä†, Yuki Mitsufuji‚Ä†
        <br>
        <em>International Conference on Learning Representations (ICLR) </em>, 2025
        <br>
        <a href="https://hero-dm.github.io/">Project Page</a>
        /
        <a href="https://arxiv.org/abs/2410.05116>Paper</a>
        <p></p>
        <p>
	To effectively and efficiently utilize human feedback, we develop a framework, HERO, which leverages online human feedback collected on the fly during model learning. Specifically, HERO features two key mechanisms: (1) an online training method that captures human feedback and provides informative learning signals for fine-tuning, and (2) generating images from SD's refined initialization samples, enabling faster convergence towards the evaluator's intent.        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <img src='img/dbc.png' style="max-width:120%;height:auto">
        </div>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <papertitle>Diffusion Model-Augmented Behavioral Cloning</papertitle>
        <be>
	<strong>Shang-Fu Chen*</strong>,
        Hsiang-Chun Wang*,
        Ming-Hao Hsu,
        Chun-Mao Lai,  
        Shao-Hua Sun,
        <br>
        <em>International Conference on Machine Learning (ICML)</em>, 2024
        <br>
        <a href="https://nturobotlearninglab.github.io/dbc/">Project Page</a>
        /
        <a href="https://arxiv.org/abs/2302.13335">Paper</a>
        /
        <a href="https://nturobotlearninglab.github.io/dbc/asset/dbc_poster_icml2023_f4lcd.pdf">Poster</a>
        <p></p>
        <p>
        This work aims to augment BC by employing diffusion models for modeling expert behaviors and designing a learning objective that leverages learned diffusion models to guide policy learning. To this end, we propose an imitation learning framework that benefits from modeling both the conditional and joint probability of the expert distribution. Our proposed diffusion model-augmented behavioral cloning (DBC) employs a diffusion model trained to model expert behaviors and learns a policy to optimize both the BC loss (conditional) and our proposed diffusion model loss (joint). Our proposed method outperforms baselines or achieves competitive performance in various continuous control domains, including navigation, robot arm manipulation, dexterous manipulation, and locomotion.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <img src='img/dg_anomaly.png' style="max-width:120%;height:auto">
        </div>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <papertitle>Domain-Generalized Textured Surface Anomaly Detection</papertitle>
        <br>
        <strong>Shang-Fu Chen</strong>,
        Yu-Min Liu,
        Chia-Ching Lin,
        Trista Pei-Chun Chen,
        Yu-Chiang Frank Wang
        <br>
        <em>IEEE International Conference on Multimedia and Expo (ICME)</em>, 2022
        <br>
        <a href="https://arxiv.org/abs/2203.12304">Paper</a>
        <p></p>
        <p>
        In this paper, we address the task of domain-generalized textured surface anomaly detection. We propose a patch-based meta-learning model that exhibits promising generalization ability. By observing normal and abnormal surface data across multiple source domains, our model can generalize to an unseen textured surface of interest and localize abnormal regions in the query images. Our experiments verify that our model performs favorably against state-of-the-art anomaly detection and domain generalization approaches in various settings.
	      </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <img src='img/dg_face.png' style="max-width:120%;height:auto">
        </div>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <papertitle>Learning Facial Liveness Representation for Domain Generalized Face Anti-spoofing</papertitle>
        <br>
        Zih-Ching Chen*,
        Lin-Hsi Tsao*,
        Chin-Lun Fu*,
        <strong>Shang-Fu Chen</strong>,
        Yu-Chiang Frank Wang
        <br>
        <em>IEEE International Conference on Multimedia and Expo (ICME)</em>, 2022
        <br>
        <a href="https://arxiv.org/abs/2208.07828">Paper</a>
        <p></p>
        <p>
          This work aims to apply domain generalization and feature disentanglement for the face anti-spoofing (FAS) problem, which aims at distinguishing face spoof attacks from authentic ones. We propose a learning frame to disentangle facial liveness representation from the irrelevant ones (i.e., facial content and image domain features). The resulting liveness representation exhibits sufficient domain invariant properties and thus can be applied for performing domain-generalized FAS. Our experiments verify that our model performs favorably against state-of-the-art approaches on five benchmark datasets with various settings.
	      </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <img src='img/gan_representation.png' style="max-width:120%;height:auto">
        </div>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <papertitle>Representation Decomposition For Image Manipulation And Beyond</papertitle>
        <br>
        <strong>Shang-Fu Chen</strong>,
        Jia-Wei Yan,
        Ya-Fan Su,
        Yu-Chiang Frank Wang
        <br>
        <em>IEEE International Conference on Image Processing (ICIP)</em>, 2021
        <br>
        <a href="https://arxiv.org/abs/2011.00788">Paper</a>
        <p></p>
        <p>
          This work aims to apply feature disentanglement on existing/trained generative models. To this end, we propose a decomposition-GAN (dec-GAN), which can decompose an existing latent representation into content and attribute features. Guided by the classifier pre-trained on the attributes of interest, our dec-GAN decomposes the attributes of interest from the latent representation, while data recovery and feature consistency objectives enforce the learning of our proposed method. Our experiments on multiple image datasets confirm the effectiveness and robustness of our dec-GAN over recent representation disentanglement models.
	      </p>
      </td>
    </tr>
    <!--
    <tr>
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <img src='img/attention_video.png' style="max-width:120%;height:auto">
        </div>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <papertitle>Learning Hierarchical Self-Attention for Video Summarization</papertitle>
        <br>
        Yen-Ting Liu,
        Yu-Jhe Li,
        Fu-En Yang,
        <strong>Shang-Fu Chen</strong>,
        Yu-Chiang Frank Wang
        <br>
        <em>IEEE International Conference on Image Processing (ICIP)</em>, 2019
        <br>
        <a href="https://ieeexplore.ieee.org/document/8803639">Paper</a>
        <p></p>
        <p>
        [Summarize]
	      </p>
      </td>
    </tr>
    -->
    <tr>
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <img src='img/rnn_multilable.png' style="max-width:120%;height:auto">
        </div>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <papertitle>Order-Free RNN with Visual Attention for Multi-Label Classification</papertitle>
        <br>
        <strong>Shang-Fu Chen*</strong>,
        Yi-Chen Chen*,
        Chih-Kuan Yeh,
        Yu-Chiang Frank Wang
        <br>
        <em>The AAAI Conference on Artificial Intelligence (AAAI)</em>, 2018
        <br>
        <a href="https://arxiv.org/abs/1707.05495">Paper</a>
        <p></p>
        <p>
          We propose a recurrent neural network (RNN) based model for image multi-label classification. Our model integrates the learning of visual attention and Long Short-Term Memory (LSTM) layers. The LSTM module learns the labels of interest and their co-occurrences, while the attention module captures the associated image regions. Unlike existing approaches, training our model does not require pre-defined label orders. We introduce a robust inference process to address the prediction error propagation problem. Our experiments on NUS-WISE and MS-COCO datasets confirm the design of our network and its effectiveness in solving multi-label classification problems.
	      </p>
      </td>
    </tr>
</tbody></table>	
	
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Special thanks to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a> for the source code of this website. 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
